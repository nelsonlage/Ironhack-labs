{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef65d31",
   "metadata": {},
   "source": [
    "# Practice web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f592e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401064e1",
   "metadata": {},
   "source": [
    "**1. Retrieve an arbitrary [Wikipedia page of \"Python\"](https://en.wikipedia.org/wiki/Python) and create a list of links on that page**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321f6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html\n",
    "wiki_python_response = requests.get('https://en.wikipedia.org/wiki/Python')\n",
    "\n",
    "# Parse html (create the soup)\n",
    "wiki_python_soup = BeautifulSoup(wiki_python_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed48507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Pythonidae',\n",
       " 'https://en.wikipedia.org/wiki/Python_(genus)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(programming_language)',\n",
       " 'https://en.wikipedia.org/wiki/CMU_Common_Lisp',\n",
       " 'https://en.wikipedia.org/wiki/PERQ#PERQ_3']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = ['https://en.wikipedia.org' + link['href'] for link in wiki_python_soup.select('#mw-content-text ul [href^=\"/wiki\"]')]\n",
    "links[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbbad61",
   "metadata": {},
   "source": [
    "**2. Find the number of titles that have changed in the [United States Code](http://uscode.house.gov/download/download.shtml) since its last release point**\n",
    "\n",
    "From the website: \"Titles in **bold** have been changed since the last release point.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b9a50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html\n",
    "us_code_response = requests.get('http://uscode.house.gov/download/download.shtml')\n",
    "\n",
    "# Parse html (create the soup)\n",
    "us_code_soup = BeautifulSoup(us_code_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5829080c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(us_code_soup.select('.usctitlechanged'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6555eec9",
   "metadata": {},
   "source": [
    "**3. Create a Python list with the top ten [FBI's Most Wanted](https://www.fbi.gov/wanted/topten) names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451ca9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html\n",
    "most_wanted_response = requests.get('https://www.fbi.gov/wanted/topten')\n",
    "\n",
    "# Parse html (create the soup)\n",
    "most_wanted_soup = BeautifulSoup(most_wanted_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7635e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RAFAEL CARO-QUINTERO',\n",
       " 'YULAN ADONAY ARCHAGA CARIAS',\n",
       " 'EUGENE PALMER',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'OCTAVIANO JUAREZ-CORRO']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wanted = [wanted.get_text().strip() for wanted in most_wanted_soup.select('.portal-type-person .title')]\n",
    "most_wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259312c5",
   "metadata": {},
   "source": [
    "**4. Display the 20 latest earthquakes info (date, time, latitude, longitude and region name) by the [EMSC](https://www.emsc-csem.org/Earthquake/) as a pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1582f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html\n",
    "earthquake_response = requests.get('https://www.emsc-csem.org/Earthquake/')\n",
    "\n",
    "# Parse html (create the soup)\n",
    "earthquake_soup = BeautifulSoup(earthquake_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae3b91",
   "metadata": {},
   "source": [
    "**Date & time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e377e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [element.get_text().split()[0] for element in earthquake_soup.select('.tabev6 a')[:20]]\n",
    "time = [element.get_text().split()[1] for element in earthquake_soup.select('.tabev6 a')[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07d988",
   "metadata": {},
   "source": [
    "First we access the tag containing the date & time information:\n",
    "```python\n",
    "earthquake_soup.select('.tabev6 a')[0]\n",
    "```\n",
    "```\n",
    ">><a href=\"/Earthquake/earthquake.php?id=1065652\">2021-11-23   09:18:39.9</a>\n",
    "```\n",
    "\n",
    "Then we `.get_text()` and `.split()` the string to retrieve the date (index `[0]`) and time (index `[1]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb236952",
   "metadata": {},
   "source": [
    "**Latitude & longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9683de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long = earthquake_soup.select('tbody tr .tabev1')\n",
    "directions = earthquake_soup.select('tbody tr :nth-child(-n+2 of .tabev2)')\n",
    "\n",
    "latitude = [lat_long[i].get_text(strip=True) + ' ' +  directions[i].get_text(strip=True) for i in range(0,40,2)]\n",
    "longitude = [lat_long[i].get_text(strip=True) + ' ' +  directions[i].get_text(strip=True) for i in range(1,41,2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6566200",
   "metadata": {},
   "source": [
    "First we access the tag containing the desired information:\n",
    "```python\n",
    "earthquake_soup.select('tbody tr .tabev1')[:4]\n",
    "```\n",
    "```\n",
    ">> [<td class=\"tabev1\">28.55 </td>, - lat\n",
    "    <td class=\"tabev1\">17.86 </td>, - long\n",
    "    <td class=\"tabev1\">37.66 </td>, - lat\n",
    "    <td class=\"tabev1\">22.87 </td>] - long \n",
    "```\n",
    "Every adjecent data is a pair (latitude, longitude). The cardinal points are located in another tag:\n",
    "```python\n",
    "earthquake_soup.select('tbody tr .tabev2')[:3]\n",
    "```\n",
    "```\n",
    ">> [<td class=\"tabev2\">N  </td>, - lat\n",
    "    <td class=\"tabev2\">W  </td>, - long\n",
    "    <td class=\"tabev2\">2.7</td>] - magnitude\n",
    "```\n",
    "This way we also return information about the magnitude. So we need to access only the first two items returned, which can be achieved using the `:nth-child()` selector:\n",
    "```python\n",
    "earthquake_soup.select('tbody tr :nth-child(-n+2 of .tabev2)')[:4]\n",
    "```\n",
    "```\n",
    ">> [<td class=\"tabev2\">N  </td>,\n",
    "    <td class=\"tabev2\">W  </td>,\n",
    "    <td class=\"tabev2\">N  </td>,\n",
    "    <td class=\"tabev2\">E  </td>]\n",
    "```\n",
    "Then we can concatenate the coordinates and cardinal points to return the latitude & longitude with a list comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159081b",
   "metadata": {},
   "source": [
    "**Region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81f9d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = [region.get_text(strip=True) for region in earthquake_soup.select('.tb_region')[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f633a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:50:09.1</td>\n",
       "      <td>33.63 S</td>\n",
       "      <td>177.52 E</td>\n",
       "      <td>NORTH OF NEW ZEALAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:49:29.5</td>\n",
       "      <td>35.51 N</td>\n",
       "      <td>22.89 E</td>\n",
       "      <td>CENTRAL MEDITERRANEAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:48:32.0</td>\n",
       "      <td>11.13 N</td>\n",
       "      <td>86.79 W</td>\n",
       "      <td>NEAR COAST OF NICARAGUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:45:15.7</td>\n",
       "      <td>28.53 N</td>\n",
       "      <td>17.84 W</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:15:06.3</td>\n",
       "      <td>28.53 N</td>\n",
       "      <td>17.82 W</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:11:10.0</td>\n",
       "      <td>21.53 S</td>\n",
       "      <td>68.51 W</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:09:16.2</td>\n",
       "      <td>28.55 N</td>\n",
       "      <td>17.86 W</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>17:03:48.1</td>\n",
       "      <td>37.67 N</td>\n",
       "      <td>22.88 E</td>\n",
       "      <td>SOUTHERN GREECE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:57:55.0</td>\n",
       "      <td>0.92 S</td>\n",
       "      <td>125.36 E</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:41:24.3</td>\n",
       "      <td>19.22 N</td>\n",
       "      <td>155.43 W</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:41:00.3</td>\n",
       "      <td>28.55 N</td>\n",
       "      <td>17.83 W</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:38:03.0</td>\n",
       "      <td>35.46 N</td>\n",
       "      <td>3.62 W</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:32:00.0</td>\n",
       "      <td>31.33 N</td>\n",
       "      <td>77.17 E</td>\n",
       "      <td>HIMACHAL PRADESH, INDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:29:06.7</td>\n",
       "      <td>28.56 N</td>\n",
       "      <td>17.79 W</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:17:34.2</td>\n",
       "      <td>38.17 N</td>\n",
       "      <td>117.96 W</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:12:35.9</td>\n",
       "      <td>52.32 N</td>\n",
       "      <td>157.30 E</td>\n",
       "      <td>KAMCHATKA PENINSULA, RUSSIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:07:20.4</td>\n",
       "      <td>28.59 N</td>\n",
       "      <td>17.79 W</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:06:08.0</td>\n",
       "      <td>3.88 N</td>\n",
       "      <td>127.00 E</td>\n",
       "      <td>KEPULAUAN TALAUD, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:03:22.5</td>\n",
       "      <td>0.17 S</td>\n",
       "      <td>78.38 W</td>\n",
       "      <td>ECUADOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-11-23</td>\n",
       "      <td>16:01:02.0</td>\n",
       "      <td>0.13 S</td>\n",
       "      <td>124.53 E</td>\n",
       "      <td>MOLUCCA SEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Time Latitude Longitude                        Region\n",
       "0   2021-11-23  17:50:09.1  33.63 S  177.52 E          NORTH OF NEW ZEALAND\n",
       "1   2021-11-23  17:49:29.5  35.51 N   22.89 E     CENTRAL MEDITERRANEAN SEA\n",
       "2   2021-11-23  17:48:32.0  11.13 N   86.79 W       NEAR COAST OF NICARAGUA\n",
       "3   2021-11-23  17:45:15.7  28.53 N   17.84 W  CANARY ISLANDS, SPAIN REGION\n",
       "4   2021-11-23  17:15:06.3  28.53 N   17.82 W  CANARY ISLANDS, SPAIN REGION\n",
       "5   2021-11-23  17:11:10.0  21.53 S   68.51 W            ANTOFAGASTA, CHILE\n",
       "6   2021-11-23  17:09:16.2  28.55 N   17.86 W  CANARY ISLANDS, SPAIN REGION\n",
       "7   2021-11-23  17:03:48.1  37.67 N   22.88 E               SOUTHERN GREECE\n",
       "8   2021-11-23  16:57:55.0   0.92 S  125.36 E                   MOLUCCA SEA\n",
       "9   2021-11-23  16:41:24.3  19.22 N  155.43 W      ISLAND OF HAWAII, HAWAII\n",
       "10  2021-11-23  16:41:00.3  28.55 N   17.83 W  CANARY ISLANDS, SPAIN REGION\n",
       "11  2021-11-23  16:38:03.0  35.46 N    3.62 W           STRAIT OF GIBRALTAR\n",
       "12  2021-11-23  16:32:00.0  31.33 N   77.17 E       HIMACHAL PRADESH, INDIA\n",
       "13  2021-11-23  16:29:06.7  28.56 N   17.79 W  CANARY ISLANDS, SPAIN REGION\n",
       "14  2021-11-23  16:17:34.2  38.17 N  117.96 W                        NEVADA\n",
       "15  2021-11-23  16:12:35.9  52.32 N  157.30 E   KAMCHATKA PENINSULA, RUSSIA\n",
       "16  2021-11-23  16:07:20.4  28.59 N   17.79 W  CANARY ISLANDS, SPAIN REGION\n",
       "17  2021-11-23  16:06:08.0   3.88 N  127.00 E   KEPULAUAN TALAUD, INDONESIA\n",
       "18  2021-11-23  16:03:22.5   0.17 S   78.38 W                       ECUADOR\n",
       "19  2021-11-23  16:01:02.0   0.13 S  124.53 E                   MOLUCCA SEA"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquake_df = pd.DataFrame({\n",
    "    'Date': date,\n",
    "    'Time': time,\n",
    "    'Latitude': latitude,\n",
    "    'Longitude': longitude,\n",
    "    'Region': region,\n",
    "    \n",
    "})\n",
    "earthquake_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0a64f",
   "metadata": {},
   "source": [
    "**5. List all language names and number of related articles in the order they appear in [wikipedia.org](https://www.wikipedia.org/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a4fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html\n",
    "wiki_response = requests.get('https://www.wikipedia.org/')\n",
    "\n",
    "# Parse html (create the soup)\n",
    "wiki_soup = BeautifulSoup(wiki_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff4d443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('English', '6,383,000+'),\n",
       " ('日本語', '1,292,000+'),\n",
       " ('Русский', '1,756,000+'),\n",
       " ('Deutsch', '2,617,000+'),\n",
       " ('Español', '1,717,000+'),\n",
       " ('Français', '2,362,000+'),\n",
       " ('中文', '1,231,000+'),\n",
       " ('Italiano', '1,718,000+'),\n",
       " ('Português', '1,074,000+'),\n",
       " ('Polski', '1,490,000+')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = [language.get_text() for language in wiki_soup.select('.central-featured-lang strong')]\n",
    "num_articles = [','.join(num.string.split()) for num in wiki_soup.select('.central-featured-lang bdi')]\n",
    "\n",
    "articles_language = list(zip(languages, num_articles))\n",
    "articles_language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984dd67",
   "metadata": {},
   "source": [
    "**Number of articles**\n",
    "\n",
    "Both `.string` and `.get_text()` return an unformated number (as string):  \n",
    "```python\n",
    "wiki_soup.select('.central-featured-lang bdi')[0].string\n",
    "```\n",
    "```\n",
    "> '6\\xa0383\\xa0000+'\n",
    "```\n",
    "\n",
    "To solve that, we can `.split()` the string and `.join()` its components using a comma as separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0529bd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Number of articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>6,383,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>日本語</td>\n",
       "      <td>1,292,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Русский</td>\n",
       "      <td>1,756,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2,617,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Español</td>\n",
       "      <td>1,717,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Français</td>\n",
       "      <td>2,362,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中文</td>\n",
       "      <td>1,231,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Italiano</td>\n",
       "      <td>1,718,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Português</td>\n",
       "      <td>1,074,000+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Polski</td>\n",
       "      <td>1,490,000+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language Number of articles\n",
       "0    English         6,383,000+\n",
       "1        日本語         1,292,000+\n",
       "2    Русский         1,756,000+\n",
       "3    Deutsch         2,617,000+\n",
       "4    Español         1,717,000+\n",
       "5   Français         2,362,000+\n",
       "6         中文         1,231,000+\n",
       "7   Italiano         1,718,000+\n",
       "8  Português         1,074,000+\n",
       "9     Polski         1,490,000+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or as a dataset\n",
    "\n",
    "articles_language_df = pd.DataFrame({\n",
    "    'Language': languages,\n",
    "    'Number of articles': num_articles\n",
    "})\n",
    "articles_language_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46d1ac82",
   "metadata": {},
   "source": [
    "**6. A list with the different kind of datasets available in [data.gov.uk](https://data.gov.uk/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ad34658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html\n",
    "uk_dataset_response = requests.get('https://data.gov.uk/')\n",
    "\n",
    "# Parse html (create the soup)\n",
    "uk_dataset_soup = BeautifulSoup(uk_dataset_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25f7f688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_datasets = [dataset.get_text() for dataset in uk_dataset_soup.select('.govuk-heading-s a')]\n",
    "uk_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d929a",
   "metadata": {},
   "source": [
    "**7. Display the [top 10 languages by number of native speakers](https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers) stored in a pandas dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d743201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download html\n",
    "top_languages_response = requests.get('https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers')\n",
    "\n",
    "# Parse html (create the soup)\n",
    "top_languages_soup = BeautifulSoup(top_languages_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c37ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [language.string for language in\n",
    "                   top_languages_soup.select('td:nth-of-type(2) [title]:not([title=\"Hindustani language\"])')[:10]]\n",
    "speakers = [number.string.strip() for number in top_languages_soup.select('td:nth-of-type(3)')[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f887a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Speakers (millions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Russian</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Western Punjabi</td>\n",
       "      <td>92.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Marathi</td>\n",
       "      <td>83.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Language Speakers (millions)\n",
       "1   Mandarin Chinese                 918\n",
       "2            Spanish                 480\n",
       "3            English                 379\n",
       "4              Hindi                 341\n",
       "5            Bengali                 300\n",
       "6         Portuguese                 221\n",
       "7            Russian                 154\n",
       "8           Japanese                 128\n",
       "9    Western Punjabi                92.7\n",
       "10           Marathi                83.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_languages = pd.DataFrame({\n",
    "    'Language': languages,\n",
    "    'Speakers (millions)': speakers\n",
    "}, index=range(1,11))\n",
    "top10_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a0a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
